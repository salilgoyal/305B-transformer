This project was done as part of the class STATS 305B ("Models and Algorithms for Discrete Data") at Stanford University. The notebook is structured as an assignment. Towards the end of the notebook, we build a transformer architecture with minimal starter code to generate Python-style code. With limited (free) compute resources, we then improve upon a baseline transformer by forcing the transformer to pay more attention to Python-specific tokens and achieve discernably better results.
